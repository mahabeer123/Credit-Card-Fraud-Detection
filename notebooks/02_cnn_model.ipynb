{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from geopy.distance import great_circle\n",
    "#loading the dataset\n",
    "fraud_train = pd.read_csv('fraudTrain.csv')\n",
    "fraud_test = pd.read_csv('fraudTest.csv')\n",
    "\n",
    "#concatenating the two datasets\n",
    "data = pd.concat([fraud_train, fraud_test]).reset_index()\n",
    "\n",
    "data.drop(data.columns[:2], axis=1, inplace=True)\n",
    "# df.head()\n",
    "# Load your dataset\n",
    "# data = pd.read_csv('fraudTest.csv')\n",
    "print(\"Original DataFrame:\")\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data.drop(['trans_date_trans_time', 'merchant', 'category', 'gender', \n",
    "           'first', 'last', 'street', 'city', 'state', \n",
    "           'job', 'dob', 'trans_num'], axis=1, inplace=True)\n",
    "# Calculate distance feature\n",
    "data['distance'] = data.apply(lambda row: great_circle((row['lat'], row['long']), \n",
    "                                                         (row['merch_lat'], row['merch_long'])).kilometers, axis=1)\n",
    "\n",
    "# Feature selection: Focus on latitude and longitude features along with other relevant features\n",
    "features = ['zip','lat', 'long', 'merch_lat', 'merch_long', 'unix_time', 'distance']\n",
    "X = data[features]\n",
    "y = data['is_fraud']  # Target variable\n",
    "normal = data[data['is_fraud']==0]\n",
    "fraud = data[data['is_fraud']==1]\n",
    "fraud_summary = data['is_fraud'].value_counts()\n",
    "\n",
    "# Print the summary\n",
    "print(\"Fraud Summary:\")\n",
    "print(fraud_summary)\n",
    "\n",
    "# For clearer labeling\n",
    "print(f\"\\nNumber of non-fraudulent transactions: {fraud_summary[0]}\")\n",
    "print(f\"Number of fraudulent transactions: {fraud_summary[1]}\")\n",
    "# Preprocess the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# # Apply SMOTE to handle class imbalance\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# # Reshape the data for CNN input (samples, time steps, features)\n",
    "# sequence_length = 5  # Define the sequence length\n",
    "# n_samples = X_resampled.shape[0] // sequence_length\n",
    "# num_features = X_resampled.shape[1]\n",
    "\n",
    "# X_reshaped = X_resampled[:n_samples * sequence_length].reshape((n_samples, sequence_length, num_features))\n",
    "# y_array = y_resampled[:n_samples * sequence_length].reshape((n_samples, sequence_length))\n",
    "# y_final = y_array[:, -1]\n",
    "\n",
    "# # Split the reshaped data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_final, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Reshape the data for CNN input (samples, time steps, features)\n",
    "sequence_length = 5  # Define the sequence length\n",
    "n_samples = X_resampled.shape[0] // sequence_length\n",
    "num_features = X_resampled.shape[1]\n",
    "\n",
    "X_reshaped = X_resampled[:n_samples * sequence_length].reshape((n_samples, sequence_length, num_features))\n",
    "# Convert y_resampled to a NumPy array for reshaping\n",
    "y_array = y_resampled.to_numpy()[:n_samples * sequence_length].reshape((n_samples, sequence_length))\n",
    "y_final = y_array[:, -1]  # Use the last value in each sequence as the target label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_final, test_size=0.2, random_state=42)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Count the occurrences of 0 and 1 in y_train\n",
    "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "print(\"Counts in y_train:\")\n",
    "print(dict(zip(unique_train, counts_train)))\n",
    "\n",
    "# Count the occurrences of 0 and 1 in y_test\n",
    "unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "print(\"\\nCounts in y_test:\")\n",
    "print(dict(zip(unique_test, counts_test)))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, classification_report, accuracy_score, confusion_matrix,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# # Reshape the data for CNN input (samples, time steps, features)\n",
    "# sequence_length = 5  # Define the sequence length\n",
    "# n_samples = X_scaled.shape[0] // sequence_length\n",
    "# num_features = X_scaled.shape[1]\n",
    "\n",
    "# X_reshaped = X_scaled[:n_samples * sequence_length].reshape((n_samples, sequence_length, num_features))\n",
    "# y_array = y_resampled.to_numpy()[:n_samples * sequence_length].reshape((n_samples, sequence_length))\n",
    "# y_final = y_array[:, -1]\n",
    "\n",
    "# # Split the reshaped data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_final, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to categorical format for multi-class problems (not needed for binary classification)\n",
    "# num_classes = len(np.unique(y_train))\n",
    "# y_train_cat = to_categorical(y_train, num_classes)\n",
    "# y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Build the CNN model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = cnn_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"\\nEvaluation Metrics for CNN:\")\n",
    "print(f\"Accuracy: {accuracy:.15f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = cnn_model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Precision: {precision:.15f}')\n",
    "print(f'Recall: {recall:.15f}')\n",
    "print(f'F1 Score: {f1:.15f}')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.title('Confusion Matrix - CNN Model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})', color='blue')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Training and Validation Accuracy Curve\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Training and Validation Loss Curve\n",
    "plt.plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# F1 Score Over Epochs\n",
    "train_f1_scores = []\n",
    "for epoch in range(1, 21):\n",
    "    temp_y_pred = (cnn_model.predict(X_train, batch_size=32) > 0.5).astype(int).flatten()\n",
    "    temp_f1 = f1_score(y_train, temp_y_pred)\n",
    "    train_f1_scores.append(temp_f1)\n",
    "\n",
    "plt.plot(range(1, 21), train_f1_scores, label='Training F1 Score', marker='o', color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Training F1 Score Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
